---
title: "vent_variation"
author: Nick Ingraham
date: today
execute: 
  echo: false
format: 
  html:
    embed-resources: true
    number-sections: true
    toc: true
    html-q-tags: true
    code-fold: true
editor: source
editor_options: 
  chunk_output_type: console
---

# Nick TO DO STILL

## CLIF Setup

### Libraries

```{r}
#| label: installing packages
#| timeit: true

packages <- c("tidyverse","ggthemes","styler","readxl","writexl","DBI","dbplyr","knitr","pandoc","janitor", "data.table", "duckdb","powerjoin","collapse","tidyfast","datapasta","fst","dtplyr","bit64","zoo","fuzzyjoin","arrow","hrbrthemes","here","table1", "rvest", "tidymodels", "pscl")

install_if_missing <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}

sapply(packages, install_if_missing)

```


### Find CLIF-1.0

```{r}

## This will search through all the files in each parent directory and stop when it finds the path to CLIF-1.0 !!!
find_up <- function(file, dir = getwd()) {
  
  if (file %in% list.files(dir)) {
    return(file.path(dir, file))
  }
  
  split_dirs <- strsplit(dir, "/")[[1]]
  
  if (length(split_dirs) == 1) {
    message("No such file exists in directory or parent directories")
    return(invisible(NULL))
  }
  
  find_up(file, paste(head(split_dirs, -1), collapse = "/"))
  
}




# get site specific information information
path_site_info <- find_up("site_specific_information.qmd")
path_site_info


```

# Running site file

```{r}
#| purl: false

source_rmd <- function(file, local = FALSE, ...){
  options(knitr.duplicate.label = 'allow')

  tempR <- tempfile(tmpdir = ".", fileext = ".R")
  on.exit(unlink(tempR))
  knitr::purl(file, output=tempR)

  envir <- globalenv()
  source(tempR, local = envir, ...)
}

source_rmd(path_site_info, echo = TRUE)



```


### Make Folders

```{r}


# Function to create directories
create_files <- function(base_path, dir_name) {
  full_path <- file.path(base_path, dir_name)
  dir.create(full_path, showWarnings = FALSE)
}

# List of directories to create
dirs_to_create <- c("temp", "clean_db", "tables", "raw_files", "figures", "output")

# Create the directories
lapply(dirs_to_create, create_files, base_path = path_current_project)


# Print the result for verification
print(paste("Directories created under:", path_current_project))

```


### [  ] Have you run the QC resp support script

```{r}



# Check the value of the variable
if (i_ran_qc_script == "no") {
  stop("The QC script has not been run. Stopping the script.")
}


```



### Functions

```{r}
#| label: Functions
#| timeit: true


# Quickly look at the data like we would in stata, default is 100
ni_peek <- function(x, n=100){
  view(head(x, n))
}

# check missing variables
ni_count_missing <- function(df, group_vars, x_var) {
  df |> 
    group_by(pick({{ group_vars }})) |> 
    summarize(
      n_miss = sum(is.na({{ x_var }})),
      .groups = "drop"
    )
}
# flights |>  count_missing(c(year, month, day), dep_time)

# look at the variables
ni_check_variables <- function(df, n=500) {
  check <- tibble(
    col_name = names(df), 
    col_type = map_chr(df, vctrs::vec_ptype_full),
    n_miss = map_int(df, \(x) sum(is.na(x)))
  )
  print(check, n=n)
}

ni_count_prop <- function(df, var, sort = TRUE) {
  df |>
    count({{ var }}, sort = sort) |>
    mutate(prop = n / sum(n)
    )
}

# Identify and create a table of duplicate rows based on encounter_id
ni_duplicate_finder <- function(df, group_vars = c(encounter_id), n=1){
df |> 
  dplyr::group_by(pick({{ group_vars }})) |> 
  filter(n() > {{ n }}) |> 
  ungroup()
}

ni_tic <- function() {
  .GlobalEnv$time_start_temp <- proc.time()
  .GlobalEnv$time_start_sys <- Sys.time()
  return(Sys.time())
}

ni_toc <- function() {
  time_end_sys <- Sys.time()
  .GlobalEnv$time_diff.time <- round(time_end_sys - time_start_sys,2)
  mylist <- list(time_diff.time, cat("Finished in",timetaken(time_start_temp),"\n"
             ))
return(print(mylist[[1]]))
}

fio2warning <- function() {
  warning("fio2 variable needed to be fixed, it was multiplied by 100!!!")
}

labwarning <- function() {
  warning("lab values are character and needed to be fixed, they were forced to numeric!!!")
}

vitalwarning <- function() {
  warning("vital values are character and needed to be fixed, they were forced to numeric!!!")
}



read_data <- function(file_path) {
  file_path_temp <- paste0(path_cliffed_files,"/", file_path, ".", file_type)
  print(file_path_temp)
  
  if (grepl("\\.csv$", file_path_temp)) {
    return(read.csv(file_path_temp))
  } else if (grepl("\\.parquet$", file_path_temp)) {
    return(arrow::read_parquet(file_path_temp))
  } else if (grepl("\\.fst$", file_path_temp)) {
    return(fst::read.fst(file_path_temp))
  } else {
    stop("Unsupported file format")
  }
}

  
```

## Import

### Cohort identification

```{r}

#~~~~~~~~~~
# ID cohort
#~~~~~~~~~

# Main Respiratory Support Table
    #~~ using readr or fst or arrow (parquet) package depending on the file type. (THESE WERE SET DURING SET UP ^^ )
clif_respiratory_support_start <- read_data("clif_respiratory_support") |> select(encounter_id, device_category, tracheostomy)
clif_limited_identifiers_start <- read_data("clif_limited_identifiers") |> select(encounter_id, admission_dttm)
clif_encounter_demographics_dispo_start <- read_data("clif_encounter_demographics_dispo") |> select(encounter_id, age_at_admission)


# getting a keep_list of encounter_ids that have vent or trach during their encounter... we will use this right_join the dfs below
df_cohort_keep <- clif_respiratory_support_start |> 
  
  # Just getting those ventilated or trach
  filter(str_to_lower(device_category) == "vent" | tracheostomy == 1) |> 
  
  # getting age at admission
  left_join(clif_encounter_demographics_dispo_start) |> 
  
  # Exclusion based on date
  left_join(clif_limited_identifiers_start) |>
  filter(
    lubridate::year(admission_dttm) >= 2020 | encounter_id == 1767475 | encounter_id == 2044432,
    lubridate::year(admission_dttm) <= 2021,
    age_at_admission >= 18,
    !is.na(age_at_admission)
    ) |>  
  select(encounter_id) |> 
  distinct()


# Function for importing files easily just with the file of the clif_table
import_df <- function(x) {
  # Construct the file path
  file_path <- paste0(path_cliffed_files,"/", x, ".", file_type)
  
  # Dynamically call the appropriate read function based on file_type
  read_function <- get(paste0("read_", file_type)) 
  
  df <- read_function(file_path) |>
    
    # right join early so files are smaller
    right_join(df_cohort_keep) |> 
    
    # unfactor things to ensure everything is lowercase
    mutate(across(where(is.factor), as.character)) |> 
    
    # get everything to lower
    mutate(across(where(is_character), tolower)) 
  
  
  
  # Find all datetime variables containing 'dttm'
  datetime_vars <- names(df)[grepl("dttm", names(df))]
  
  # Check and convert datetime variables
  for (var in datetime_vars) {
    if (!inherits(df[[var]], "POSIXct")) {
      
      # Attempt to parse datetime using a common format, adjust based on your actual format
      df[[var]] <- mdy_hms(df[[var]], quiet = TRUE)
      
      # Check if it just turned things into NA
      if (is.na(ffirst(df[[var]], na.rm = TRUE))) {
        stop(paste("Conversion failed for:", var,"\n","\nPlease look at your clif data for   ", var, "\nmake sure its POSIXct format!!"))
        
        
        # Check if conversion failed (if it's still not POSIXct)
        if (!inherits(df[[var]], "POSIXct")) {
          stop(paste("Conversion failed for:", var,"\n","\nPlease look at your clif data for   ", var, "\nmake sure its POSIXct format!!"))
          
        }
        
      }
    }
    print(paste("Woohoo",var,"is in the correct dttm format!!"))
  }
  
  # Join with cohort data and glimpse the result
  df <- df %>% 
    right_join(df_cohort_keep) %>% 
    glimpse()
  
  # Assign the dataframe to a new variable in the global environment named after the file_name
  assign(x, df, envir = .GlobalEnv)
}


```



### Other imports / check variable alignment

```{r}

#~~~~~~~~~~
# Import data and cohort tables
#~~~~~~~~~~


# Resp support table cohort
clif_respiratory_support <- import_df("clif_respiratory_support") |> 
      # Check if Variables match!!
      # You will get an error if you do not have all the relevant variables needed
      select(
        encounter_id,
        recorded_dttm,
        device_name,
        device_category,
        mode_name,
        mode_category,
        fio2_set,
        tidal_volume_set,
        resp_rate_set,
        pressure_control_set, # not used
        pressure_support_set,
        flow_rate_set,  # not used
        # peak_inspiratory_pressure_set, # not used and only in infants
        inspiratory_time_set, # not used
        peep_set,
        tidal_volume_obs,
        plateau_pressure_obs,
        peak_inspiratory_pressure_obs,
        # peep_obs, # not used and not in adult set 
        minute_vent_obs,
        tracheostomy)


# ADT File to merge with patient so we can get hospital ID
clif_adt <- import_df("clif_adt") |> 
      # Check if Variables match!!
      select(
        encounter_id,
        location_name,
        location_category,
        in_dttm,
        out_dttm,
        hospital_id)

# Vitals to merge with patient so we can get BMI information
clif_vitals <- import_df("clif_vitals") |> 
      # Check if Variables match!!
      select(
        encounter_id,
        recorded_dttm,
        vital_name,
        vital_category,
        vital_value,
        meas_site_name)


# GCS for lap2
clif_gcs <- import_df("clif_gcs") |> 
      # Check if Variables match!!
      select(
        encounter_id,
        recorded_dttm,
        gcs_eye,
        gcs_verbal,
        gcs_motor,
        gcs_total
        )

# Labs to merge with patient so we can get spo2 and such information
clif_labs <- import_df("clif_labs") |> 
      # Check if Variables match!!
      select(
        encounter_id,
        lab_order_dttm,
        lab_result_dttm,
        lab_group,
        lab_category,
        lab_name,
        lab_value,
        reference_unit,
        lab_type_name)

# Demographics 
clif_patient_demographics <- import_df("clif_patient_demographics") |> 
      # Check if Variables match!!
      select(
        encounter_id,
        patient_id,
        sex,
        race,
        ethnicity)


# Encounter Information 
clif_encounter_demographics_dispo <- import_df("clif_encounter_demographics_dispo") |> 
      # Check if Variables match!!
      select(encounter_id,
             # admission_category, # don't have this yet in CLIF
             disposition_category,
             disposition_name,
             age_at_admission)



# Encounter Information 
clif_limited_identifiers <- import_df("clif_limited_identifiers") |>
      # Check if Variables match!!
      select(encounter_id,
             admission_dttm,
             discharge_dttm)



# combining them to one df
clif_demographics_combined <- clif_patient_demographics |> 
  left_join(clif_encounter_demographics_dispo) |> 
  left_join(clif_limited_identifiers)



# # Procedures (don't need for now, just for checking trach data at some point)
# clif_procedures <- import_df("clif_procedures") |>
#       # Check if Variables match!!
#       c(encounter_id,
#         procedure_name,
#         start_time,
#         hcup_category)     # UMN variable... may want to implement in CLIF... just need to link HCUP table to PX codes

```


# Import QA checks

```{r}

# Check fio2_set
fio2_mean <- mean(clif_respiratory_support$fio2_set, na.rm = TRUE) 

# fixing if its less than one
# You will get a warning but it will be fixed on its own with IF statement
if(fio2_mean < 1){ 
  fio2warning()
  clif_respiratory_support <- clif_respiratory_support |> mutate(fio2_set = fio2_set * 100)
  }


# Check Values of labs and vitals
if(is.character(clif_labs$lab_value)){
  labwarning()
  clif_labs <- clif_labs |> 
    mutate(lab_value = as.numeric(parse_number(lab_value)))
}


# Check Values of labs and vitals
if(is.character(clif_vitals$vital_value)){
  vitalwarning()
  clif_vitals <- clif_vitals |> 
    mutate(vital_value = as.numeric(parse_number(vital_value)))
}

```


# Cleaning Data

## Hourly Sequence

```{r}
#| label: cleaning up vent data


#~~~~~~~~~~~~~~~~
##~~ getting an hour sequence so we can fill in the gaps
#~~~~~~~~~~~~~~~~
## This is just encounter ID and recorded times at xx:59:59
## data that occurs last in the hour when there are multiple data points 
## in the end ... we will want this to be the data we use to fill the next hour... if time is NOT unified... you could have hour sequence that is 12:01, 1:01 everywhere and even when there IS data you risk filling in from the hour before and not getting the NEW data during that hour.
# if we set all the new seq hours to 59:59 then you can fill those in without risking other data when you fill in and do distinct (take the first of the hour for everything).  Remember.  Even hours with 1 data will have a new hour seq row that may be before or after the data... so doing the 59:59 puts it at the end!!!
# 

hour_sequence <- 
  clif_respiratory_support |> 
  group_by(encounter_id)  |> 
  reframe(recorded_dttm = seq(fmin(recorded_dttm), fmax(recorded_dttm), by = "1 hour")) |> 
  
  # Making it so that we get the new recorded times at the very end of the hour
  mutate(recorded_dttm = recorded_dttm - (minutes(minute(recorded_dttm))) +
           minutes(59) + seconds(59)
  ) |> 
  # getting hour and date columns for grouping
  mutate(recorded_date = date(recorded_dttm),
         recorded_hour = hour(recorded_dttm))
```


## Quality Check & Clean + Waterfall

```{r}

ni_tic()
#~~~~~~~~~~~~~~~~
##~~ Quick QA and fixing missing values throughout
#~~~~~~~~~~~~~~~~

df_resp_support  <- clif_respiratory_support |> 
  select(encounter_id, recorded_dttm, device_category, device_name, mode_category, mode_name, 
         fio2_set, tidal_volume_set, peep_set,  pressure_support_set, resp_rate_set, tracheostomy, 
         tidal_volume_obs, peak_inspiratory_pressure_obs, minute_vent_obs, plateau_pressure_obs 
  ) |>
  
  # filter is recorded_dttm missing
  mutate(
    # fio2_set
    fio2_set = fifelse(fio2_set > 100, NA_real_, fio2_set),
    fio2_set = fifelse(fio2_set <  21, NA_real_, fio2_set),
    
    # Set tidal_volume_set
    tidal_volume_set = fifelse(tidal_volume_set > 2500, NA_real_, tidal_volume_set),
    tidal_volume_set = fifelse(tidal_volume_set <   50, NA_real_, tidal_volume_set),
    
    # peep_set
    peep_set = fifelse(peep_set > 30, NA_real_, peep_set),
    peep_set = fifelse(peep_set <  0, NA_real_, peep_set),
    
    # pressure_support_set (sometimes APRV may be in here ... so limit ~ 50??)
    pressure_support_set = fifelse(pressure_support_set > 50, NA_real_, pressure_support_set),
    pressure_support_set = fifelse(pressure_support_set <  0, NA_real_, pressure_support_set),
    
    # resp_rate_set
    resp_rate_set = fifelse(resp_rate_set > 60, NA_real_, resp_rate_set),
    resp_rate_set = fifelse(resp_rate_set <  0, NA_real_, resp_rate_set),
    
    # tidal_volume_obs
    tidal_volume_obs = fifelse(tidal_volume_obs > 2500, NA_real_, tidal_volume_obs),
    tidal_volume_obs = fifelse(tidal_volume_obs <    0, NA_real_, tidal_volume_obs),
    
    # peak_inspiratory_pressure_obs
    peak_inspiratory_pressure_obs = fifelse(peak_inspiratory_pressure_obs > 60, NA_real_, peak_inspiratory_pressure_obs),
    peak_inspiratory_pressure_obs = fifelse(peak_inspiratory_pressure_obs <  0, NA_real_, peak_inspiratory_pressure_obs),
    
    # minute_vent_obs
    minute_vent_obs = fifelse(minute_vent_obs > 30, NA_real_, minute_vent_obs),
    minute_vent_obs = fifelse(minute_vent_obs <  0, NA_real_, minute_vent_obs),
    
    ) |>
  
  # getting data and hour information
  mutate(recorded_date = date(recorded_dttm),
         recorded_hour = hour(recorded_dttm)) |> 
  
  # getting hospital ID for each hour
  dplyr::left_join( #tidy_table doesn't like it when you use join_by() with between (Dropped tidy_table 2_2024) 
    clif_adt |> 
      select(encounter_id, hospital_id, location_name, location_category, in_dttm, out_dttm),
    by = join_by(encounter_id, between(recorded_dttm, in_dttm, out_dttm))
  ) |> 

  # order for filling things in
  arrange(encounter_id, recorded_dttm) |> 
  
  # Fixing when: ventilator is the device_name and will make consisent with mechanical ventilator (added 7/2024)
  mutate(
    device_name = 
      fifelse(
        device_name == "ventilator",
        "mechanical ventilator",
        device_name
      )
  ) |> 
  
  # Fixing when: the mode and category are there with device_name and device_cat not filled in.  fixing with the below
  mutate(
    device_category = 
      fifelse(
        is.na(device_category) & is.na(device_name) &
          str_detect(mode_category, "assist control-volume control|simv|pressure control"),
        "vent",
        device_category
      ),
    device_name = 
      fifelse(
        str_detect(device_category, "vent") & is.na(device_name) &
          str_detect(mode_category, "assist control-volume control|simv|pressure control"),
        "mechanical ventilator",
        device_name
      ),
  ) |>
  
  # fixing other vent things
  #     If device before is VENT + normal vent things ... its VENT too 
  mutate(device_category = fifelse(is.na(device_category) & 
                                     lag(device_category == "vent") & 
                                     tidal_volume_set > 1 & 
                                     resp_rate_set > 1 & 
                                     peep_set > 1, 
                                   "vent", 
                                   device_category)) |>
  
  #     If device after is VENT + normal vent things ... its VENT too 
  mutate(device_category = fifelse(is.na(device_category) & 
                                     lead(device_category == "vent") & 
                                     tidal_volume_set > 1 & 
                                     resp_rate_set > 1 & 
                                     peep_set > 1, 
                                   "vent", 
                                   device_category)) |> 
  
  # same as above for device_name ^^^^^^^^^^^
  mutate(device_name = fifelse(is.na(device_name) & lag(device_name == "mechanical ventilation") & tidal_volume_set > 1 & resp_rate_set > 1 & peep_set > 1, "mechanical ventilation", device_name)) |> 
  
  mutate(device_name = fifelse(is.na(device_name) & lead(device_name == "mechanical ventilation") & tidal_volume_set > 1 & resp_rate_set > 1 & peep_set > 1, "mechanical ventilation", device_name)) |>
  
  
  # doing this for BiPAP as well 
  mutate(device_category = fifelse(is.na(device_category) & 
                                     lag(device_category == "nippv") & 
                                     minute_vent_obs > 1 & 
                                     peak_inspiratory_pressure_obs > 1 & 
                                     pressure_support_set > 1, 
                                   "nippv", 
                                   device_category)) |>
  
  mutate(device_category = fifelse(is.na(device_category) & 
                                     lead(device_category == "nippv") & 
                                     minute_vent_obs > 1 & 
                                     peak_inspiratory_pressure_obs > 1 & 
                                     pressure_support_set > 1, 
                                   "nippv", 
                                   device_category)) |>
  
  

  # there are times when its clearly back to CMV (resp set and volume is set but no one puts a mode back in... just leaves it blank)
  # this is usually after pressure support ... we need to classify this now as CMV. 
  # only exception to this should be when it says trach
  # There are also some without device_cat or name and they have all the variables... these should be changed too 
  mutate(
    device_category = 
      fifelse(
        is.na(device_category) & 
          !str_detect(device_name, "trach") &
          tidal_volume_set > 0 & 
          resp_rate_set > 0,
        "vent",
        device_category
      ), 
    device_name = 
      fifelse(
        is.na(device_name) & 
          !str_detect(device_name, "trach") &
          tidal_volume_set > 0 & 
          resp_rate_set > 0,
        "mechanical ventilator",
        device_name
      ),    
    mode_category = 
      fifelse(
        is.na(mode_category) & 
          !str_detect(device_name, "trach") &
          tidal_volume_set > 0 & 
          resp_rate_set > 0,
        "assist control-volume control",
        mode_category
      ),
    mode_name = 
      fifelse(
        is.na(mode_name) & 
          !str_detect(device_name, "trach") &
          tidal_volume_set > 0 & 
          resp_rate_set > 0,
        "cmv/ac",
        mode_name)
  ) |> 
  
  
  # when there are duplicate times...
  group_by(encounter_id, recorded_dttm) |> 
  
  # when bipap is part of a duplicate we need to get rid of it... 
  #     its usually when a vent is STARTED and device is carried over but it goes to a new line with lots of NAs
  #     the NA line above has the vent settings.  Its best to just drop the nippv line when its a duplicate
  #     if we don't do this... the vent settings get sent backwards across all bipap

  mutate(n = n()) |>  
  filter(
    #  essentially this is... DROP if n>1 and device_cat == nippv
    !(n > 1 & device_category == "nippv")) |> 
  
  # redo n so we keep vent settings from above... now NAs are bad around other things and we should just drop
  mutate(n = n()) |> 
  filter(
    #  essentially this is... DROP if n>1 and device_cat == NA
    !(n > 1 & is.na(device_category))) |> 
  

  
  # filter if missing everything  
  filter(
    #  essentially this is... DROP if everything missing
    !(is.na(device_category) & 
        is.na(device_name) &
        is.na(mode_category) &
        is.na(mode_name) & 
        is.na(fio2_set) &        # keeps informative fio2_set data around
        is.na(tidal_volume_set)    # keeps vent data around... this happens sort of often
      )) |> 
    
    

  # dropping duplicates for everything else but just taking the first one
  #       ffirst works WAY faster than fill up and down and slicing(1)
  ffirst() |> 
  ungroup() |> # technically don't need this  
    
  
  # bring in hour sequences
  bind_rows(hour_sequence) |>

#~~~~~~~~~~~~~~~~
##~~ Filling in data based on a waterfall of categories to ensure accuracy
#~~~~~~~~~~~~~~~~
  # organizing
  arrange(encounter_id, recorded_dttm) |> 
  relocate(encounter_id, recorded_dttm, recorded_date, recorded_hour) |> 
  
  # fill forward device category
  group_by(encounter_id) |> 
  arrange(encounter_id, recorded_dttm) |> 
  fill(device_category) |>
  ungroup() |> 
  
  # Record a new device_category when either (a) a new encounter, or (b) preceded by a...   
  # different device category
  mutate(
    # need to have NA as something so it gets an ID
    device_cat_f = fifelse(is.na(device_category), "missing", device_category), # cant have anything with NAs when factoring
    device_cat_f = as.integer(as.factor(device_cat_f)), # need an integer for this
    
    # getting IDs
    device_cat_id = fcumsum((
      encounter_id    != flag(encounter_id, fill = TRUE) |           # (a)
        device_cat_f  != flag(device_cat_f, fill = TRUE)))) |>       # (b)
  
  relocate(device_cat_id, .after = recorded_hour) |> 
  
  # fill device name
  #         changed some failsafes above 4/2024 so its ok to do downup with this now
  group_by(encounter_id, device_cat_id) |> 
  arrange(encounter_id, recorded_dttm) |> 
  fill(device_name, .direction = "downup") |> 
  ungroup() |> 
  
  
  # Record a new device_id when either (a) a new encounter, or 
  #                                    (b) preceded by a different device name.
  mutate(
    # need to have NA as something so it gets an ID
    device_name_f = fifelse(is.na(device_name), "missing", device_name), # cant have anything with NAs when factoring
    device_name_f = as.integer(as.factor(device_name_f)), # need an integer for this
    
    # getting IDs
    device_id = fcumsum((
      encounter_id    != flag(encounter_id, fill = TRUE) |           # (a)
        device_name_f != flag(device_name_f, fill = TRUE)))) |>      # (b)
  
  relocate(device_id, .after = recorded_hour) |> 
  
  # fill mode_category (downup)
  # there are PST that are being carried over to days before when ppl get REINTUBATED
  group_by(encounter_id, device_id) |> 
  arrange(encounter_id, recorded_dttm) |> 
  fill(mode_category, .direction = "downup") |> 
  ungroup() |> 
  
  # Create mode_id
  mutate(
    mode_cat_f = fifelse(is.na(mode_category), "missing", mode_category), # cant have anything with NAs when factoring
    mode_cat_f = as.integer(as.factor(mode_cat_f)), # need an integer for this
    
    mode_cat_id = fcumsum((
      device_id     != flag(device_id, fill = TRUE) |        # (a)
        mode_cat_f  != flag(mode_cat_f, fill = TRUE)))) |>   # (b)
  
  
  relocate(mode_cat_id, .after = recorded_hour) |> 
  
  # fill mode name (downup) 
  group_by(encounter_id, mode_cat_id) |> 
  arrange(encounter_id, recorded_dttm) |> 
  fill(mode_name, .direction = "downup") |> 
  ungroup() |>  
  
  # Create mode name id
  mutate(
    mode_name_f = fifelse(is.na(mode_name), "missing", mode_name), # cant have anything with NAs when factoring
    mode_name_f = as.integer(as.factor(mode_name_f)), # need an integer for this
    
    mode_name_id = fcumsum((
      mode_cat_id != flag(mode_cat_id, fill = TRUE) |               # (a)
        mode_name_f != flag(mode_name_f, fill = TRUE)))) |>         # (b)
  
  relocate(mode_name_id, .after = recorded_hour) |> 
  
  
  # changing fio2_set to 0.21 if room air as category
  mutate(fio2_set = if_else(is.na(fio2_set) & device_category == "room air", 21, fio2_set)) |> 
  
  # erroneous set volumes are in places where they shouldn't be for PS and trach_dome
  mutate(
    tidal_volume_set = fifelse(
      (
        mode_category == "pressure support/cpap" &    # needs to be PS/CPAP
          !is.na(pressure_support_set)                    # needs to have a PS level
      ) |
        (
          is.na(mode_category) &                      # mode cat needs to be NA
            str_detect(device_name, "trach")          # only when trach stuff
        ) |
        (
          mode_category == "pressure support/cpap" &  # needs to be PS/CPAP
            str_detect(device_name, "trach")          # only when trach stuff
        ),
      NA_integer_,
      tidal_volume_set),
    
    
  ) |>
  
  # there are ppl with t-piece that should be blow_by
  mutate(mode_category = fifelse(
    (is.na(mode_category) & 
       str_detect(device_name, "t-piece")),
    "blow by",
    mode_category
  )) |> 
  
  # carry forward the rest
  group_by(encounter_id, mode_name_id) |>  # mode_name_id is the most granular, can go up and down
  arrange(encounter_id, recorded_dttm) |> 
  
  # took trach out of this so we don't fill back up 3/2024
  fill(c(fio2_set, peep_set, tidal_volume_set, pressure_support_set, resp_rate_set,
         tidal_volume_obs, peak_inspiratory_pressure_obs,  minute_vent_obs, 
         hospital_id, location_name, location_category, in_dttm, out_dttm
  ), .direction = "downup"
  ) |>
  
  # fill trach... only down
  fill(c(tracheostomy), .direction = "down") |>
  ungroup() |> 
  
  # need to get rid of duplicates 
  distinct() |> 
  select(
    encounter_id,
    recorded_dttm,
    recorded_date,
    recorded_hour,
    mode_name_id,
    device_category,
    device_name,
    mode_category,
    mode_name,
    mode_cat_id,
    device_id,
    device_cat_id,
    fio2_set,
    peep_set,
    tracheostomy,
    tidal_volume_set,
    pressure_support_set,
    resp_rate_set,
    tidal_volume_obs,
    # pressure_meanairway,
    peak_inspiratory_pressure_obs,
    plateau_pressure_obs,
    # obs_resp_rate,
    minute_vent_obs,
    hospital_id,
    location_name,
    location_category,
    # in_dttm,
    # out_dttm,
    # device_cat_f,
    # device_name_f,
    # mode_cat_f,
    # mode_name_f,
  ) 

ni_toc()
```


```{r}

### remaining issues
# [ ]  Issue with what to do when there are PS numbers with Trach Dome... should we show it as PS or leave blank



df_resp_support |> glimpse() 
# df_resp_support |> count(device_category, device_name) |> arrange(-n) |> print(n=1000)
# df_resp_support |> count(mode_category, mode_name) |> arrange(-n)
# df_resp_support |> count(device_category, device_name, mode_category, mode_name) |> arrange(-n)
# df_resp_support |> filter(is.na(device_category)) |> count(device_category, device_name, mode_category, mode_name) |> ni_peek(1000)


## this is just a stopping point so you can come back and work below 
## just run things before "Cleaning Data" and you can start below if its been saved once!
write_parquet(df_resp_support, "clean_db/df_resp_support.parquet")


```


## Vitals / ibw / labs

```{r}


######################
##~~ clean vitals and get ibw
######################

# quickly get back to things without doing the above
if(!exists("df_resp_support")){
  df_resp_support <- read_parquet("clean_db/df_resp_support.parquet")
}

##~~~~~~~~~~~~~
##~~ spo2
##~~~~~~~~~~~~~

df_spo2 <- clif_vitals |> 
  
  # getting spo2
  filter(vital_category == "spo2") |> 
  
  # making those columns
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm),
    names_from = vital_category,
    values_from = vital_value,
    values_fn = function(x) mean(x, na.rm = TRUE)
  ) |> 
  
  # getting date so we can group by this
  mutate(recorded_date = date(recorded_dttm),
         recorded_hour = hour(recorded_dttm)) |> 
  
  # taking the min spo2 by  DAY and HOUR and ENCOUNTER 
  group_by(encounter_id, recorded_date, recorded_hour) |> 
  summarize(spo2 = fmin(spo2, na.rm = TRUE)) |> 
  ungroup() |> 
  select(encounter_id, recorded_date, recorded_hour, spo2)
  

##~~~~~~~~~~~~~
##~~ pao2 / sao2
##~~~~~~~~~~~~~

df_pao2 <-  clif_labs |> 
    filter(lab_category %in% c("pao2",
                             "sao2")) |> 
  select(encounter_id, recorded_dttm = lab_result_dttm, lab_category, lab_value) |>

  # getting pao2 / sao2
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm),
    names_from = lab_category,
    values_from = lab_value,
    values_fn = function(x) mean(x, na.rm = TRUE)
  ) |> 
  
    # getting date so we can group by this
  mutate(recorded_date = date(recorded_dttm),
         recorded_hour = hour(recorded_dttm)) |> 
  
  # grouping by day
  group_by(encounter_id, recorded_date) |> 
  summarize(pao2 = fmin(pao2, na.rm = TRUE),
            sao2 = fmin(sao2, na.rm = TRUE)
            ) |> 
  ungroup() |> 
      # getting date so we can group by this
  mutate(recorded_hour = hour(recorded_date)) |> 
  select(encounter_id, recorded_date, recorded_hour, pao2, sao2)

##~~~~~~~~~~~~~
##~~ ibw
##~~~~~~~~~~~~~

df_ibw <- clif_vitals |> 
  
  # getting height and spo2
  filter(vital_category == "height_inches") |> 
  
  # making those columns
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm),
    names_from = vital_category,
    values_from = vital_value,
    values_fn = function(x) mean(x, na.rm = TRUE)
  ) |> 

  group_by(encounter_id) |> 
  
  # taking the first height DAY and ENCOUNTER
  summarise(height_inches = ffirst(height_inches, na.rm = TRUE)) |> 
  ungroup() |> 
  
  # get biological sex
  left_join(clif_patient_demographics |> 
             select(encounter_id, sex)
            ) |> 
  
  # Calculate ibw for males
  mutate(ibw = fifelse(sex == "male" & height_inches > 56, 50 + (2.3 * (height_inches - 60)), NA_real_)) |>  # 1st % of male = 60 inches
  
  # Calculate ibw for females
  mutate(ibw = fifelse(sex == "female" & height_inches > 56, 45.5 + (2.3 * (height_inches - 60)), ibw)) |>  # 1st % of female = 56 inches
  
  # Remove records with height less than 40
  # This also removes those without a height for the whole admission, which is ok... can't do LTVV without height known
  filter(height_inches >= 40) |>  # assumming these are kiddos and/or amputees which means IBW will be inaccurate
  group_by(encounter_id) |> 
  
  # using first ibw for the encounter
  mutate(ibw = ffirst(ibw, na.rm = TRUE)) |> 
  
  # getting only the variables we want
  select(encounter_id, ibw, sex) |> 
  ungroup() |> 
  distinct()


```


## Trach Variation

```{r}

   # getting trach hospital (first one with trach == 1)
trach_hospital_id <- df_resp_support |> 
  filter(tracheostomy == 1) |> 
  select(encounter_id, recorded_date, trach_hospital_id = hospital_id) |> 
  arrange(encounter_id, recorded_date) |> 
  group_by(encounter_id) |> 
  mutate(trach_hospital_id = ffirst(trach_hospital_id)) |> 
  select(encounter_id, trach_hospital_id) |> 
  distinct() 

  # get the first trach day by encounter only
trach_day1 <- df_resp_support |> 
  filter(tracheostomy == 1) |> 
  select(encounter_id, recorded_date) |> 
  arrange(encounter_id, recorded_date) |> 
  group_by(encounter_id) |> 
  mutate(trach_day1 = fmin(recorded_date, na.rm = TRUE)) |> 
  select(encounter_id, trach_day1) |> 
  distinct() 

  # get the first ventilator day by encounter only
vent_day1 <- df_resp_support |> 
  filter(device_category == "vent") |> 
  select(encounter_id, recorded_date) |> 
  arrange(encounter_id, recorded_date) |> 
  group_by(encounter_id) |> 
  mutate(vent_day1 = fmin(recorded_date, na.rm = TRUE)) |> 
  select(encounter_id, vent_day1) |> 
  distinct() 
  
df_trach_variation <- df_resp_support |> 
  # keep encounters that have a tracheostomy
  mutate(tracheostomy_max = fmax(tracheostomy, na.rm = TRUE),
         .by = encounter_id) |> 
  filter(tracheostomy_max == 1) |> 
  
  # getting vent days or trach days ONLY
  filter(device_category == "vent" | tracheostomy == 1) |> 
  
  select(encounter_id, recorded_date, tracheostomy) |> 
  distinct() |> 
  
  arrange(encounter_id, recorded_date) |> 
  
  # getting vent day count
  ungroup() |> 
  
  # getting vent day count because some ppl might have days OFF the vent in between if we just do min(vent_day)
  group_by(encounter_id) |> 
  
  # this will give 1, 2, 3, 4, 5 as long as its the same encounter_id and trach is NA
  # once trach == 1 it parks at that max number so we can just take max
  # also... we can drop those with vent_day_count == 0 because that means they had the trach on vent day 1!!!
  mutate(vent_day_count = fcumsum(
    is.na(tracheostomy)
  )) |> 
  left_join(trach_day1) |> 
  left_join(vent_day1) |> 
  left_join(trach_hospital_id) |> 
  
  # get rid of those with zero vent_day_count (aka they were trached the whole time)
  filter(vent_day_count > 0) |> 
  select(encounter_id, trach_hospital_id, trach_day1, vent_day1, vent_day_count) |> 
  mutate(vent_day_count_max = max(vent_day_count, na.rm = TRUE)) |> 
  
  # true "trach_day" is vent_day_count_max - 1 because we didn't have a vent_day_zero... we started at 1
  mutate(vent_days_before_trach = vent_day_count_max - 1) |> 
  
  mutate(
  trach_day = difftime(trach_day1, vent_day1, units = "days")
    ) |>
  select(encounter_id, trach_hospital_id, vent_days_before_trach) |> 
  ungroup() |>
  distinct()

df_trach_variation |> glimpse()
  
```


## CLIF hourly level data

```{r}

##~~~~~~~~~~~~~
##~~ Hourly Data
##~~~~~~~~~~~~~

df_hourly_resp_support1 <- df_resp_support |> 
  mutate(recorded_month = month(recorded_dttm),
         recorded_year = year(recorded_dttm)) |> 
  
  #~~ use recorded time to arrange these in order
  arrange(encounter_id, recorded_dttm) |> 
  
  # change recorded_dttm to be the same thing at the end of the hour so we can do calculations later
  group_by(encounter_id, recorded_date, recorded_hour) |> 
  mutate(recorded_dttm_hour_end = flast(recorded_dttm)) |> 
  ungroup() |> 
  
  #~~ vent sequence variable
      # only go up in number if (a) new category & (b) its a vent category
      # could add a gap to this as well for like hours and such
  arrange(encounter_id, recorded_date) |> 
  mutate(gap_vent_hours = fifelse(
    device_category == "vent" | tracheostomy == 1,
    as.numeric(difftime(lead(recorded_dttm_hour_end), recorded_dttm_hour_end, units = "hours")),
    NA_real_
  )) |> 
  
  group_by(encounter_id) |> 
  mutate(
    device_category_f = fifelse(is.na(device_category), "missing", device_category), # cant have anything with NAs when factoring
    device_category_f = as.integer(as.factor(device_category_f)), # need an integer for this
    
    # you step to the next vent sequence if
    #    1) its a vent
    #    2) its a NEW device cat
    #    3) trach is na
    #    4) gap is <= 6
    vent_episode_id = fcumsum(
      device_category == "vent" & 
        flag(device_category_f, fill = TRUE) != device_category_f &
        is.na(tracheostomy) & 
        gap_vent_hours <= 6
    )) |> 
  ungroup() 

df_hourly_resp_support2 <- df_hourly_resp_support1 |> 
  
  # currently those with trach right away are zeros for vent_id
  # those without vent or were subsequent after vent are currently the same number as the vent before
  mutate(
    # change those not with trach/vent to NA
    vent_episode_id = fifelse(
      device_category == "vent" | tracheostomy == 1,
      vent_episode_id,
      NA_real_
    ),
    
    # we could also drop these patients if we wanted to 
    # change those trach'd on day1 without vent beforehand to enc_sequence 1
    vent_episode_id = fifelse(
      tracheostomy == 1 & vent_episode_id == 0,
      1,
      vent_episode_id
    )
  ) |> 
  
  # getting vent hour per sequence
  group_by(encounter_id, vent_episode_id) |> 
  mutate(vent_episode_hour_seq = fcumsum(
    recorded_dttm_hour_end != flag(recorded_dttm_hour_end, fill = TRUE))
  ) |>
  # fix those not vent back to NA
  mutate(vent_episode_hour_seq = fifelse(is.na(vent_episode_id), NA_real_, vent_episode_hour_seq)) |> 
  
  
  # get max hours per vent sequence... want to drop those <=24
  mutate(vent_episode_duration_hours = fmax(vent_episode_hour_seq, na.rm = TRUE)) |>
  
  ungroup() |> 
  
  # getting vent hour per sequence per hospital
  #   there are times when that episode crosses hospitals
  #   for hospital summary we need duration split up by hospital
  group_by(encounter_id, vent_episode_id, hospital_id) |> 
  mutate(vent_episode_hospital_hour_seq = fcumsum(
    recorded_dttm_hour_end != flag(recorded_dttm_hour_end, fill = TRUE))
  ) |> 
  
  
  # fix those not vent back to NA
  mutate(vent_episode_hospital_hour_seq = fifelse(is.na(vent_episode_id), NA_real_, vent_episode_hospital_hour_seq)) |> 
  
  
  # get max hours per vent sequence... want to drop those <=24
  mutate(vent_episode_hospital_duration_hours = fmax(vent_episode_hospital_hour_seq, na.rm = TRUE)) |>
  
  ungroup() |> 
  

  # final variables
  select(
  encounter_id,
  recorded_date,
  recorded_hour,
  recorded_dttm_hour_end,
  vent_episode_id,
  vent_episode_hour_seq,
  vent_episode_duration_hours,
  vent_episode_hospital_hour_seq,
  vent_episode_hospital_duration_hours,
  # recorded_dttm,
  device_category,
  device_name,
  mode_category,
  mode_name,
  fio2_set,
  recorded_month,
  recorded_year,
  peep_set,
  tracheostomy,
  tidal_volume_set,
  hospital_id,
  location_name,
  location_category,
  pressure_support_set,
  resp_rate_set,
  tidal_volume_obs,
  # pressure_meanairway,
  peak_inspiratory_pressure_obs,
  plateau_pressure_obs,
  # obs_resp_rate,
  minute_vent_obs,
  ) |>
  
  #~~ group by hour so that we can take the first time point to get our information
  # this will only keep the first row if there are duplicates
  distinct(encounter_id, recorded_date, recorded_hour, .keep_all = TRUE) |> 
  left_join(df_ibw) |> 
  left_join(df_spo2) |> 
  
  # those without ibw need to be dropped... they won't have biological sex either (this drops whole encounters)
  filter(!is.na(ibw)) |> 
  
  group_by(encounter_id) |>
  arrange(encounter_id, recorded_dttm_hour_end) |> 

  
  # getting each hour in sequence of their hospital stay
  mutate(enc_hour_seq = fcumsum(recorded_dttm_hour_end != flag(recorded_dttm_hour_end, fill = TRUE))) |>
  
  # getting the CALENDAR sequence... purely based on date... so day 1 can be 3 hours
  mutate(enc_calendar_date_seq = fcumsum(recorded_date != flag(recorded_date, fill = TRUE))) |>
  
  # getting DAY sequence based on which hour it is... so everyone will be 24 hours in for day 1 etc
  # Will mainly use this metric to use
  mutate(enc_day_seq = ceiling(enc_hour_seq/24)) |> 
  ungroup() |> 
  
  # merge trach variation data
  left_join(df_trach_variation) |> 
  filter(!is.na(hospital_id))


ni_toc()
  
df_hourly_resp_support <- df_hourly_resp_support2 |> 
   # final variables
    select(
      encounter_id,
      # recorded_date,
      # recorded_hour,
      # recorded_dttm_hour_end,
      vent_episode_id,
      vent_episode_hour_seq,
      vent_episode_duration_hours,
      vent_episode_hospital_hour_seq,
      vent_episode_hospital_duration_hours,
      device_category,
      device_name,
      mode_category,
      mode_name,
      fio2_set,
      recorded_month,
      recorded_year,
      peep_set,
      tracheostomy,
      tidal_volume_set,
      hospital_id,
      location_name,
      location_category,
      ibw,
      sex,
      spo2,
      enc_hour_seq,
      enc_calendar_date_seq,
      enc_day_seq,
      trach_hospital_id,
      vent_days_before_trach
      )


# duplicate check
# df_hourly_resp_support |> group_by(pick(colnames(df_hourly_resp_support))) |> filter(n() > 1) 

write_parquet(df_hourly_resp_support, "clean_db/df_hourly_resp_support.parquet")


rm(clif_vitals)
gc()


```





## Fig 1 Mode Variation --> Frequency and Density of Vent Mode by hospitals

```{r}


if(!exists("df_hourly_resp_support")){
  df_hourly_resp_support <- read_parquet("clean_db/df_hourly_resp_support.parquet")
}


##~~~~~~~~~~~~~
##~~ Hospital Summary
##~~~~~~~~~~~~~

## data should be at the hourly level for each patient encounter
# Calculate normalized counts
mode_hospital_summary_table <- df_hourly_resp_support |> 
  filter(device_category == "vent" & location_category == "icu") |> 
  filter(!is.na(mode_category)) |> 
  group_by(hospital_id) |> 
  summarise(count = n()) |> 
  # Normalizing counts
  mutate(normalized_count = count / fmax(count, na.rm = TRUE),
         # need to have NA in the data given its in the universal aesthetic
         mode_category = NA)  |> 
  arrange(-count) |> 
  ungroup()

write_parquet(mode_hospital_summary_table, paste0("tables/mode_hospital_summary_table",clif_institution,".parquet"))


##~~~~~~~~~~~~~
##~~ Graph df
##~~~~~~~~~~~~~

mode_hourly_resp_support <- df_hourly_resp_support |> 
    filter(
      # recorded_year == 2019 &
      device_category == "vent" &  
        location_category == "icu"  # take out operating room ventilation
    ) |> 
    
    filter(!is.na(mode_category)) |>   # only 0.7% for vent device
   mutate(
      mode_category = fct_infreq(mode_category),
      hospital_id_graph = fct_infreq(hospital_id)
    ) |> 
  select(hospital_id_graph, mode_category)

mode_hourly_resp_support_table <- mode_hourly_resp_support |> 
  count(hospital_id_graph, mode_category)
  
test_mode <- mode_hourly_resp_support_table |> 
  uncount(n) 

write_parquet(mode_hourly_resp_support_table, paste0("tables/mode_hourly_resp_support_table_",clif_institution,".parquet"))

```


```{r}


# Nick will run the below on the table you saved with all data together
# ... so no need to save the graph
# Left the code  so you can explore your own data

# Create a bar plot with ggplot2
ggplot(
  mode_hourly_resp_support,  aes(x = hospital_id_graph, fill = mode_category)) +
  geom_bar(position = "fill") +
  # Use labs to add a title and remove the axis labels
  labs(title = "Ventilator Modes by Hospital", x = "Hospital", y = "Proportion of Mode Category") + 
  # Use theme_minimal to create a minimal theme
  theme_minimal() +
  # adjusting tick marks for x axis
  theme(axis.text.x = element_text(angle = 30, hjust = 1, vjust = 1)) +
  # Add the summary data as a layer with a dummy aesthetic for color
  geom_point(data = mode_hospital_summary_table, aes(x = hospital_id, y = normalized_count, color = "Total Counts"), size = 3) +
  # Add horizontal lines at the height of each point, only spanning the width of the bar
  geom_errorbar(data = mode_hospital_summary_table, aes(x = hospital_id, ymin = normalized_count, ymax = normalized_count, group = 1, color = "Total Counts"),
                width = 0.9,  # Adjust this value to change the width of the horizontal lines
                linewidth = 0.5) +  # Adjust size for line thickness
  # geom_line(data = mode_hospital_summary_table, aes(x = hospital_id_graph, y = normalized_count, group = 1, color = "Total Counts"), linewidth = 1) +
  # Customize the legend for the dummy aesthetic
  scale_color_manual(name = "Legend", values = c("Total Counts" = "black"),
                     labels = c("Total Counts" = "Total Mode Counts (Normalized)")) +
  guides(fill = guide_legend(title = "Ventilator Mode Category", override.aes = list(color = NA)), 
         color = guide_legend(title = "")) +
  scale_fill_discrete(breaks = c("assist control-volume control", 
                                 "pressure support/cpap", 
                                 "pressure-regulated volume control",
                                 "pressure control", 
                                 "simv", 
                                 "blow by"))






```

## Fig 2 Trach Variation --> Estimated Day of ventilation of Trach placement by hospitals

```{r}

# clean up trach days
 trach_variation <- df_hourly_resp_support |> 
  filter(!is.na(vent_days_before_trach)) |> 
  select(encounter_id, trach_hospital_id, vent_days_before_trach) |> 
  ungroup() |>
  distinct()


trach_variation_table <- trach_variation |>
  count(trach_hospital_id, vent_days_before_trach)
  
test_trach <- trach_variation_table |> 
  uncount(n) 

write_parquet(trach_variation_table, paste0("tables/trach_variation_table_",clif_institution,".parquet"))

```


```{r}

# Nick will run the below on the table you saved with all data together
# ... so no need to save the graph
# Left the code  so you can explore your own data
# 
# 
trach_excl_early_trach <- trach_variation |> filter(vent_days_before_trach > 3)

# Create a boxplot
ggplot(trach_variation, aes(x = trach_hospital_id, y = vent_days_before_trach)) +
  geom_boxplot() +
  labs(title = "Variation in Tracheostomy Ventilator Day Across Hospitals",
       x = "Hospital",
       y = "Ventilator Day for Tracheostomy")


# Create a violin plot
ggplot(trach_variation, aes(x = trach_hospital_id, y = vent_days_before_trach)) +
  geom_violin() +
  labs(title = "Variation in Tracheostomy Ventilator Day Across Hospitals",
       x = "Hospital",
       y = "Ventilator Day for Tracheostomy")


ggplot(trach_variation, aes(x = trach_hospital_id, y = vent_days_before_trach, fill = factor(trach_hospital_id))) +
  # geom_boxplot(width = 0.1, fill = "white", outlier.shape = NA) + # Hide outliers for the boxplot
  # geom_jitter(width = 0.2, size = 1.5, alpha = 0.4) +
  geom_violin(adjust = 2) +
  labs(title = "Variation in Tracheostomy Ventilator Day Across Hospitals",
       x = "Hospital",
       y = "Ventilator Day for Tracheostomy") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  # theme_light() +
  guides(fill = guide_legend(title = "Hospital ID"))


# trach_variation |> filter(vent_days_before_trach > 30) |> View()

```


## Fig 3 Initial Set Volume / ibw Variation 

```{r}

ltvv_variation <- df_hourly_resp_support |> 
  # keep only those on vent and exclude non-icu times
  filter(device_category == "vent" & location_category == "icu") |> 
  
  # need at least 24 hours of ventilation
  filter(vent_episode_duration_hours >= 24) |> 
  
  # getting Vt by ibw
  mutate(vt_cckg = tidal_volume_set / ibw) |> 
  mutate(vt_bin = case_when(
    vt_cckg <  4            ~"< 4 cc/kg",
    vt_cckg <  5            ~"4-5 cc/kg",
    vt_cckg <  6            ~"5-6 cc/kg",
    vt_cckg <  7            ~"6-7 cc/kg",
    vt_cckg <  8            ~"7-8 cc/kg",
    vt_cckg <  9            ~"8-9 cc/kg",
    vt_cckg <  10           ~"9-10 cc/kg",
    vt_cckg <  11           ~"10-11 cc/kg",
    vt_cckg <  12           ~"11-12 cc/kg",
    vt_cckg >= 12           ~">= 12 cc/kg",
    TRUE                    ~NA,
  )) |> 
  mutate(
    vt_bin = factor(vt_bin, levels = rev(c("< 4 cc/kg", "4-5 cc/kg",
                                           "5-6 cc/kg", "6-7 cc/kg",
                                           "7-8 cc/kg" , "8-9 cc/kg",
                                           "9-10 cc/kg", "10-11 cc/kg",
                                           "11-12 cc/kg", ">= 12 cc/kg")))
  ) |> 

  # remove those without tidal_volume_sets
  filter(!is.na(tidal_volume_set)) |> glimpse() 


ltvv_variation_table <- ltvv_variation |> 
  count(hospital_id, vt_bin)

test_ltvv <- ltvv_variation_table |> 
  uncount(n) 

write_parquet(ltvv_variation_table, paste0("tables/ltvv_variation_table_",clif_institution,".parquet"))
```


```{r}

# Nick will run the below on the table you saved with all data together
# ... so no need to save the graph
# Left the code  so you can explore your own data

icu_hosp_ranks_8cc <- ltvv_variation |> 
  group_by(hospital_id) |> 
  mutate(count_hosp = n()) |> 
  group_by(hospital_id, vt_bin, count_hosp) |> 
  summarise(count_bin = n()) |> 
  ungroup() |>
  filter(vt_bin %in% c("8-9 cc/kg","9-10 cc/kg", "10-11 cc/kg", "11-12 cc/kg", ">= 12 cc/kg")) |> 
  group_by(hospital_id) |> 
  mutate(pct_over_8 = sum(count_bin) / count_hosp) |> 
  select(hospital_id, pct_over_8) |> 
  distinct() |>
  arrange(pct_over_8) |>  
  pull(hospital_id)



ltvv_variation |> 
  filter(hospital_id %in% icu_hosp_ranks_8cc) |> 
  mutate(hospital_id = factor(hospital_id, levels = rev(icu_hosp_ranks_8cc))) |> 
  ggplot(aes(y = hospital_id, fill = vt_bin )) + 
  geom_bar(position = "fill") + 
  scale_fill_brewer(palette = "RdBu", direction = 1) +
  ggthemes::theme_gdocs() + 
  labs(x = "Percentage of patient-hours of volume control ventilation",
       y = "Hospital",
       fill = "")
ggsave("figures/variation_in_vent_under_8cc_sort.pdf")



```


## Table 1 CLIF patient characteristics

```{r}


#TABLE FUNCTIONS
clif_med = function(v)
{
  a=  paste(round(median(v, na.rm = TRUE), digits =1), " (", deframe(round(quantile(v, na.rm = TRUE), digits =1)[2]), "-", deframe(round(quantile(v, na.rm = TRUE), digits = 1)[4]), ")", sep = "")
  return(a)
}

clif_counts = function(v)
{
  a=  paste(sum(v, na.rm=TRUE), " (", round(mean(v, na.rm=TRUE)*100, digits=1), ")", sep = "")
  return(a)
}

clif_mean_r = function(v)
{
  a=  paste(round(mean(v, na.rm = TRUE), digits=1), " (", round(sd(v, na.rm = TRUE), digits=1), ")", sep = "")
  return(a)
}


clif_demographics_table_start <- df_hourly_resp_support |> 
  select(encounter_id, tracheostomy, hospital_id, vent_episode_id, vent_episode_hospital_duration_hours) |> 
  
  # taking the first round of MV only
  filter((vent_episode_id == 1)) |> 
  select(-vent_episode_id) |> 
  distinct() |> 
  
  # bring in demographics
  left_join(clif_demographics_combined) |> 
  filter(!is.na(age_at_admission)) |> 
  filter(!is.na(hospital_id)) |> 
  # fix forward slashes in hospital
  mutate(hospital_id = str_replace(hospital_id, "/", " ")) |> 
  filter(sex %in% c("male", "female"))  |> 
  rename(age = age_at_admission) |> 
  mutate(race = fifelse(race == "unknown", "other", race)) |> 
  mutate(death = as.integer(grepl("dead|expired|death|died", disposition_category, ignore.case = TRUE))) |> 
  mutate(
    
    # fixing up race
    race_f = 
      fcase(
        grepl("black|african[-]american", race, ignore.case = TRUE)   , "Black",
        grepl("white|caucasian", race, ignore.case = TRUE)            , "White",
        grepl("asian", race, ignore.case = TRUE)                      , "Asian",
        default                                                       = "Other"
      ),
    
    # fixing up ethnicity
    ethnicity_f = 
      fcase(
        grepl("(non|not)[-\\s]*(hispanic|latino|latinx|hisp)", ethnicity, ignore.case = TRUE), "Non Hispanic",
        default = "Hispanic"
      )
  ) |> 
  
  # getting max trach for encounter
  group_by(encounter_id) |> 
  mutate(tracheostomy = fmax(tracheostomy, na.rm = TRUE)) |> 
  mutate(tracheostomy = fifelse(tracheostomy == 1, 1, 0, 0)) |> 
  ungroup() |> 
  distinct() |> 
  mutate(across(where(is.character), str_to_title)) |> 
  mutate(across(where(is.character), as.factor))

hospitals <- clif_demographics_table_start |> select(hospital_id) |> distinct() |> pull()

for (hosp in hospitals) {
  clif_demographics_table_start_hosp <- clif_demographics_table_start |> filter(hospital_id == hosp)
  # HTML content (make sure your actual HTML string is correctly input here)
  html_content <- table1(~ age + sex + race + ethnicity + death + tracheostomy + vent_episode_hospital_duration_hours, data = clif_demographics_table_start_hosp)
  
  # Use rvest to read the HTML table
  table <- read_html(html_content) %>%
    html_table(fill = TRUE)
  
  # The first element of the list should be your table
  df <- table[[1]]
  
  # Rename 'Overall(N=14598)' to 'fabc(N=14598)' using the site variable
  names(df) <- gsub("Overall\\(N=(\\d+)\\)", paste0(hosp, ' ', "(N=\\1)"), names(df))
  write.csv(df, paste0("tables/table1_", hosp, '.csv'), row.names = FALSE)
  
}

# 
# 
# table_summary <- clif_demographics_table_start |> 
#   group_by(hospital_id) |> 
#   summarise(N = n(), 
#             Age               = clif_mean_r(age_at_admission),
#             "Sex, female"     = clif_counts(sex == "female"),
#             Race              = "",
#             Black             = paste0("  ", clif_counts(race == "black or african-american")),
#             White             = paste0("  ", clif_counts(race == "white")),
#             Asian             = paste0("  ", clif_counts(race == "asian")),
#             Other             = paste0("  ", clif_counts(!race %in% c("black or african-american", "white", "asian"))),
#             "Ethnicity, Hispanic"   = clif_counts(ethnicity == "hispanic"),
#             
#             "Ventilator Days" = clif_med(vent_episode_hospital_duration_hours/24),
#             "Mortality"       = clif_counts(death)
#   ) |> 
#   mutate(hospital_id = str_to_title(hospital_id)) |> 
#   rename(Hospital = hospital_id)
# 
# 
# characteristics <- colnames(table_summary)
# # table_summary <- as.data.frame(t(table_summary))
# # characteristics
# 
# # leaving it without transposing it yet
# table_summary
# write_parquet(table_summary, paste0("tables/hospital_table_summary_",clif_institution,".parquet"))


```


## Men vs Women Tidal Volume Ventilation

```{r}

ltvv_female <- ltvv_variation |> 
  left_join(clif_demographics_combined |> select(sex, encounter_id)) |> 
  filter(!sex == "Unknown") 

  
ltvv_variation |> 
  filter(hospital_id %in% icu_hosp_ranks_8cc) |> 
  mutate(hospital_id = factor(hospital_id, levels = rev(icu_hosp_ranks_8cc), labels = rev(str_to_title(icu_hosp_ranks_8cc)))) |> 
  mutate(sex = factor(sex,
                      levels = c("male", "female"),
                      labels = c("Male", "Female"))) |> 
  filter(vt_cckg<15) |> 
  
  ggplot(aes(x = hospital_id, y = vt_cckg, fill = sex )) + 
  # bw options c("nrd0", "nrd", "ucv", "bcv", "SJ-ste", "SJ-dpi"),
    geom_violin(position="dodge", bw = "bcv", alpha=0.4, trim = TRUE, scale = "width", draw_quantiles = c(0.5)) +
  # scale_fill_brewer(palette = "RdBu", direction = 1) +
  labs(
    title = "Set tidal volume in first 24 hours by hospital",
    x = "Hospital",
    y = "Set Tidal Volume (cc/kg)"
  ) +
      theme_ipsum(axis_title_just = "m",
                  axis_title_size =  15)  +

  # theme_minimal() + # This theme provides a clean and modern look to the plot
  scale_fill_manual(values = c("Male" = "blue", "Female" = "green")) + # Manual colors for gender  
theme(
  legend.title = element_blank(),
  plot.background = element_blank(),
  panel.grid = element_blank(),
  panel.background = element_blank(),
  panel.grid.major = element_blank(), 
               panel.grid.minor = element_blank(),
  axis.title.y = (element_text(margin = margin(r = 20))),
  axis.title.x = (element_text(margin = margin(t = 20)))
)

  

```


# Laps2 Score


## encounter data

```{r}

clif_adt_hospital <-  clif_adt |>
  mutate(location_category = factor(location_category,
                                    levels = (c("icu", "floor", "ed", "or", "l&d", "ltach", "imaging", "other")),
                                    ordered = TRUE)) |> 
  group_by(encounter_id) |> 
  arrange(encounter_id, location_category, in_dttm) |> 
  slice_head(n=1) |> 
  ungroup() |> 
  select(encounter_id,
         hospital = hospital_id)


clif_adt_admit <-  clif_adt |>
  group_by(encounter_id) |> 
  arrange(encounter_id, in_dttm) |> 
  slice_head(n=1) |> 
  ungroup() |> 
  select(encounter_id,
         first_location_category = location_category)
  

# fixing clif_labs to recorded_dttm
if ("lab_result_dttm" %in% colnames(clif_labs)) {
  clif_labs <- clif_labs |> rename(recorded_dttm = lab_result_dttm)
}

df_encounter_laps2_temp1 <- clif_limited_identifiers |> 
  left_join(clif_encounter_demographics_dispo) |> 
  left_join(clif_patient_demographics) |> 
  left_join(clif_adt_hospital) |> 
  left_join(clif_adt_admit) |> 
  
  # make dead/hospice column
  mutate(
    death_or_hospice_01 = fcase(
      disposition_category %in% 
        c("hospice", "dead", "expired", "died")       , 1,
      default                                         = 0
    ),
    
    death_or_hospice_01       = as.factor(death_or_hospice_01),
    
    # make 24 hours after admission variable (to collect data from first 24 hours)
    dt_24hours_after_admit    = admission_dttm + hours(24),
    
    # ED binary variable
    ed_admit_01               = fifelse(str_detect(first_location_category, "ed"), 1, 0, 0),
          # I think we used categorical in Rachel Kohn paper... Pat uses ED y/n
          # admission source OR you can use ED variable
    # Admit source variable (use one or the other)
    # admission_category      = as.factor(admission_category),  don't have this yet
    
    # sex
    female_01                 = fifelse(str_detect(sex, "female"), 1, 0, 0),
    
  )


```

## prelaps

```{r}

############
# Pre-Laps... want the most recent within 24 hours of admission
############
df_pre_laps2_prep1 <- 
  df_encounter_laps2_temp1 |> 
  left_join(clif_labs |> 
              filter(lab_category %in% c("anion_gap",
                                         "carbon_dioxide", # FROM BMP
                                         "bun",
                                         "creatinine",
                                         "sodium")),
            
            # join only if between the first 24 hours
            by = join_by(encounter_id, 
                         dt_24hours_after_admit >= recorded_dttm) 
  ) |> 
  # Min/Max
  #     bun            max
  #     creatinine     min
  #     bun/cr         max
  #     bun/cr         most recent (prelaps)
  #     anion_gap      max
  #     carbon_dioxide min
  #     ag/bicarb      most recent (prelaps)
  #     sodium         min
  #     sodium         most recent (prelaps)
       
  group_by(encounter_id, recorded_dttm, lab_category) |> 
  # using obs lets you get away with duplicates when going wider and can fix later!
  mutate(obs = row_number()) |> 
  ungroup() |> 
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm, obs),
    names_from = lab_category,
    values_from = lab_value,
    # names_prefix = "lab_wide_",
    # values_fill = NA
  ) |>
  
  # Quick min/max for duplicates at the SAME time
  select(-obs) |> 
  distinct() 

# find the duplicates by recorded_dttm
df_pre_laps2_prep2 <- df_pre_laps2_prep1 |> 
  arrange(encounter_id, recorded_dttm) |> 
  group_by(encounter_id, recorded_dttm) |>
  # mutate(n = n()) |> 
  # filter(n > 1) |> 
  summarise(
    bun               = fmax(bun, na.rm = TRUE),
    creatinine        = fmin(creatinine, na.rm = TRUE),
    carbon_dioxide    = fmin(carbon_dioxide, na.rm = TRUE),
    anion_gap         = fmax(anion_gap, na.rm = TRUE),
    sodium            = fmin(sodium, na.rm = TRUE),

    .groups = "drop"
  ) |> 
  
  # replace inf with NAs
  mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 
  
  # get rid of duplicate rows
  distinct() |> 

# df_pre_laps2_prep2 <- df_pre_laps2_prep1 |> 
#   anti_join(df_pre_laps2_duplicates |> 
#               select(encounter_id, recorded_dttm),
#             join_by(encounter_id, recorded_dttm)) |> 
#   bind_rows(df_pre_laps2_duplicates) |> 
  
  # order appropriately for when getting last labs for "most recent"
  arrange(encounter_id, recorded_dttm) |> 
  
  # carry forward
  group_by(encounter_id) |> 
  
  # fill in ... its only the first 24 hours so its ok
  fill(c(bun,
         creatinine,
         carbon_dioxide,
         anion_gap,
         sodium), 
       .direction = "downup") |>
  
  # ? time shift if needed
  
  # get the most recent lab (aka last) based on recorded_dttm
    mutate(
      bun_recent                = flast(bun),
      creatinine_recent         = flast(creatinine),
      carbon_dioxide_recent     = flast(carbon_dioxide),
      anion_gap_recent          = flast(anion_gap),
      sodium_recent             = flast(sodium)
           ) |> 
  ungroup() |> 
  select(encounter_id, ends_with("recent")) |> 

  # final pre-laps labs needed
  mutate(
    # make ratios
    sodium              = sodium_recent,
    bun_cr_ratio        = bun_recent/creatinine_recent,
    ag_hco3_ratio       = (anion_gap_recent/carbon_dioxide_recent)*1000
  ) |> 
  select(-ends_with("recent")) |> 
  
  # replace inf with NAs (sometimes it happens when divided by zero)
  mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 
  
  distinct()
  



# replacing all the admission values that are missing with normal values
        # replace BUNCREAT_RECENT_24=8 if BUNCREAT_RECENT_24==. // 4724
        # replace NA_RECENT_24=135 if NA_RECENT_24==. // 4270
        # replace AGHCO3_RECENT_24=200 if AGHCO3_RECENT_24==. // 5103
        
 df_pre_laps_merging <- df_pre_laps2_prep2 |> 
   left_join(
     df_encounter_laps2_temp1 |> 
       select(
         encounter_id,
         admission_dttm,
         age = age_at_admission,
         female_01,
         ed_admit_01,
         # admission_category,
         death_or_hospice_01
       ) |> 
       distinct(),
     join_by(encounter_id)
   ) |> 
   mutate(
    age_cat = case_when(
      age >= 85 ~ 5,
      age >= 75 ~ 4,
      age >= 65 ~ 3,
      age >= 40 ~ 2,
      TRUE ~ 1
    )
  ) |> 
   mutate(
      # impute to normal (8)
    bun_cr_ratio = fifelse(is.na(bun_cr_ratio), 8, bun_cr_ratio),
     
    buncreat_cat = case_when(
      bun_cr_ratio        >= 24 ~ 4,
      bun_cr_ratio        >= 16 ~ 3,
      bun_cr_ratio        < 8   ~ 2,
      TRUE                      ~ 1
    )
  ) |> 
     mutate(
      # impute to normal (135)
    sodium = fifelse(is.na(sodium), 135, sodium),
    na_cat = case_when(
      sodium            >= 155  ~ 7,
      sodium            >= 149  ~ 6,
      sodium            >= 146  ~ 5,
      sodium            >= 132  ~ 4,
      sodium            >= 129  ~ 3,
      sodium            < 129   ~ 2,
      TRUE                      ~ 1
    )
  ) |> 
     mutate(
      # impute to normal (200)
    ag_hco3_ratio = fifelse(is.na(ag_hco3_ratio), 200, ag_hco3_ratio),
    aghco3_cat = case_when(
      ag_hco3_ratio        >= 600  ~ 4,
      ag_hco3_ratio        >= 400  ~ 3,
      ag_hco3_ratio        < 200   ~ 2,
      TRUE                         ~ 1,
    )
  )
 
 # logistic regression to obtain p(death/hospice)
 lr_model <-
  glm(
    death_or_hospice_01 ~
      age +
      female_01 +
      ed_admit_01 +
      bun_cr_ratio +
      sodium +
      ag_hco3_ratio,
    family = "binomial",
    data   = df_pre_laps_merging
  )

tidy(lr_model)
pR2(lr_model)["McFadden"]

df_pre_laps_final  <- df_pre_laps_merging |> 
  mutate(p_death = predict(lr_model, df_pre_laps_merging, type = "response")) |> 
  mutate(
    high_risk = case_when(
      p_death >= 0.06 ~ 1,
      TRUE ~ 0
    )) %>%
  select(encounter_id, p_death, high_risk)

```


The above has like 58% high risk... that seems too high
See testing below but ultimately I think its ok to use the predictions as above and not the published ones below.  
R2 is 17 (using GLM) vs 11 (using numbers from Escobar study) when doing glm(death ~ p_death) in isolation.  Despite having a high number of high risk (58% with glm vs 10% with escobar numbers), i think it will work out ok


## laps2 labs ALL

```{r}
##~~~~~~~~~~~~~~~~~~~~~
# LAPS2 time
##~~~~~~~~~~~~~~~~~~~~~
 
df_laps2_prep1 <- 
  df_encounter_laps2_temp1 |> 
  select(encounter_id, admission_dttm, discharge_dttm) |> 
  distinct() |> 
  # slice_head(n=1000) |> 
  left_join(clif_labs |> 
              filter(lab_category %in% c("albumin",
                                     "anion_gap",
                                     "bilirubin_total",
                                     "bun",
                                     "carbon_dioxide",
                                     "creatinine",
                                     "glucose_serum",
                                     "hematocrit",
                                     "hemoglobin",
                                     "lactic_acid",
                                     "paco2",
                                     "pao2",
                                     "ph_arterial",
                                     "platelet_count",
                                     "sao2",
                                     "sodium",
                                     "troponin",
                                     "wbc")) |> 
              select(-lab_order_dttm),
            
            # join only if between the first 24 hours
            by = join_by(encounter_id)) |> 
  # making all hemoglobin into hematocrits
  mutate(lab_value = fifelse(lab_category == "hemoglobin", lab_value*3, lab_value)) |> 
  mutate(lab_category = fifelse(lab_category == "hemoglobin", "hematocrit", lab_category)) |> 
  
    # using obs lets you get away with duplicates when going wider and can fix later!
  group_by(encounter_id, recorded_dttm, lab_category) |> 
  mutate(obs = row_number()) |> 
  ungroup() |> 
  
  # pivot wider to get columns
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm, obs),
    names_from = lab_category,
    values_from = lab_value,
    # names_prefix = "lab_wide_",
    # values_fill = NA
  ) |>
  
  # Quick min/max for duplicates at the SAME time
  select(-obs) |> 
  mutate(lab_date = date(recorded_dttm)) |> 
  distinct() 

ni_tic()
# find the duplicates by day
df_laps2_prep2 <- df_laps2_prep1 |>
  # arrange(encounter_id, recorded_dttm) |>
  group_by(encounter_id, lab_date) |>
  # mutate(n = n()) |>
  # filter(n > 1) |>
  summarise(
    albumin             = fmin(albumin, na.rm = TRUE),
    anion_gap           = fmax(anion_gap, na.rm = TRUE),
    bilirubin_total     = fmax(bilirubin_total, na.rm = TRUE),
    bun                 = fmax(bun, na.rm = TRUE),
    carbon_dioxide      = fmin(carbon_dioxide, na.rm = TRUE),
    creatinine          = fmax(creatinine, na.rm = TRUE),
    glucose_serum       = fmin(glucose_serum, na.rm = TRUE),
    hematocrit          = fmax(hematocrit, na.rm = TRUE),
    lactic_acid         = fmax(lactic_acid, na.rm = TRUE),
    paco2               = fmax(paco2, na.rm = TRUE),
    pao2                = fmax(pao2, na.rm = TRUE),
    ph_arterial         = fmin(ph_arterial, na.rm = TRUE),
    platelet_count      = fmin(platelet_count, na.rm = TRUE),
    sao2                = fmin(sao2, na.rm = TRUE),
    sodium              = fmin(sodium, na.rm = TRUE),
    troponin            = fmax(troponin, na.rm = TRUE),
    wbc                 = fmin(wbc, na.rm = TRUE
    ), 

    .groups = "drop"
  ) |> 
  
    # bun_cr_ratio
  mutate(
    bun_cr_ratio = bun / creatinine
  ) |> 
  
    mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 
  # get rid of duplicate rows
  distinct() 




# |> 
#   group_by(encounter_id) |> 
#   # carryforward after prelaps imputation
#     fill(c(
#       albumin,
#       anion_gap,
#       bilirubin_total,
#       bun,
#       carbon_dioxide,
#       creatinine,
#       glucose,
#       hematocrit,
#       lactic_acid,
#       paco2,
#       pao2,
#       ph_arterial,
#       platelet_count,
#       sao2,
#       sodium,
#       troponin,
#       wbc,
#       ), 
#       .direction = "down") |>
  
  ni_toc()


            
```

## Labs day one

```{r}
df_laps2_dayone_prep1 <- 
  df_encounter_laps2_temp1 |> 
  select(encounter_id, admission_dttm, discharge_dttm, dt_24hours_after_admit) |> 
  distinct() |> 
  left_join(clif_labs |> 
              filter(lab_category %in% c("albumin",
                                     "anion_gap",
                                     "bilirubin_total",
                                     "bun",
                                     "carbon_dioxide",
                                     "creatinine",
                                     "glucose_serum",
                                     "hematocrit",
                                     "hemoglobin",
                                     "lactic_acid",
                                     "paco2",
                                     "pao2",
                                     "ph_arterial",
                                     "platelet_count",
                                     "sao2",
                                     "sodium",
                                     "troponin",
                                     "wbc")) |>            
              select(-lab_order_dttm),
            
            # join only if between the first 24 hours
            by = join_by(encounter_id, 
                         dt_24hours_after_admit >= recorded_dttm)
  ) |> 

  # making all hemoglobin into hematocrits
  mutate(lab_value = fifelse(lab_category == "hemoglobin", lab_value*3, lab_value)) |> 
  mutate(lab_category = fifelse(lab_category == "hemoglobin", "hematocrit", lab_category)) |> 
  
  group_by(encounter_id, recorded_dttm, lab_category) |> 
  # using obs lets you get away with duplicates when going wider and can fix later!
  mutate(obs = row_number()) |> 
  ungroup() |> 
  
  # pivot wider to get columns
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm, obs, admission_dttm),
    names_from = lab_category,
    values_from = lab_value,
    # names_prefix = "lab_wide_",
    # values_fill = NA
  ) |>
  
  # Quick min/max for duplicates at the SAME time
  select(-obs) |> 
  distinct() 

# get min/max
df_laps2_dayone_prep2 <- df_laps2_dayone_prep1 |>
  arrange(encounter_id, recorded_dttm) |> 
  
  # filter out those without a recorded_dttm so we don't add a date later
  filter(!is.na(recorded_dttm)) |> 
  # if we make "lab_date" the encounter date... then we are switching all labs within 24hr of admission to the "day 1" in a sneaky fashion
  mutate(lab_date = date(admission_dttm)) |> # make it all the same day 1
  group_by(encounter_id, lab_date) |>
  # mutate(n = n()) |>
  # filter(n > 1) |>
  summarise(
    albumin             = fmin(albumin, na.rm = TRUE),
    anion_gap           = fmax(anion_gap, na.rm = TRUE),
    bilirubin_total     = fmax(bilirubin_total, na.rm = TRUE),
    bun                 = fmax(bun, na.rm = TRUE),
    carbon_dioxide      = fmin(carbon_dioxide, na.rm = TRUE),
    creatinine          = fmax(creatinine, na.rm = TRUE),
    glucose_serum       = fmin(glucose_serum, na.rm = TRUE),
    hematocrit          = fmax(hematocrit, na.rm = TRUE),
    lactic_acid         = fmax(lactic_acid, na.rm = TRUE),
    paco2               = fmax(paco2, na.rm = TRUE),
    pao2                = fmax(pao2, na.rm = TRUE),
    ph_arterial         = fmin(ph_arterial, na.rm = TRUE),
    platelet_count      = fmin(platelet_count, na.rm = TRUE),
    sao2                = fmin(sao2, na.rm = TRUE),
    sodium              = fmin(sodium, na.rm = TRUE),
    troponin            = fmax(troponin, na.rm = TRUE),
    wbc                 = fmin(wbc, na.rm = TRUE
    ),

    .groups = "drop"
  ) |> 
  
    # bun_cr_ratio
  mutate(
    bun_cr_ratio = bun / creatinine
  ) |> 
  
    # replace inf with NAs
  mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 

    # get rid of duplicate rows
  distinct() 



# switch out the day 1 stuff 
df_laps2_final <- df_laps2_prep2 |> anti_join(df_laps2_dayone_prep2 |> 
                              select(encounter_id, lab_date)) |> 
  bind_rows(df_laps2_dayone_prep2) |> 
  arrange(encounter_id, lab_date) |> 
  

  # filter out NA for lab date
  filter(!is.na(lab_date))

  
```


## GCS


```{r}



df_gcs_merge_ready <- clif_gcs |>
  mutate(vital_value = case_when(
    gcs_total %in% c(14, 15)                ~ 1,
    gcs_total %in% c(8, 9, 10, 11, 12, 13)  ~ 3,
    gcs_total %in% c(2, 3, 4, 5, 6, 7)      ~ 4,
    TRUE                                    ~ NA   # we account for this when doing the points later
  )) |>
  mutate(vital_category = "gcs") |> 
  select(encounter_id,
         vital_category,
         recorded_dttm,
         vital_value,
         )


df_vitals_gcs <- clif_vitals |>
              filter(vital_category %in% c("temp_f",
                                       "sbp",
                                       "spo2",
                                       "pulse",
                                       "respiration")) |>
              select(-meas_site_name) |> 
              
                          # get gcs in there now
              bind_rows(df_gcs_merge_ready)


```

## vitals all

```{r}

df_laps2_vitals_prep1 <- 
  df_encounter_laps2_temp1 |> 
  select(encounter_id, admission_dttm, discharge_dttm) |>
  distinct() |> 
  left_join(df_vitals_gcs,
            
            # join by the encounter ID
            by = join_by(encounter_id)) |> 
  
    group_by(encounter_id, recorded_dttm, vital_category) |> 
  # using obs lets you get away with duplicates when going wider and can fix later!
  mutate(obs = row_number()) |> 
  ungroup() |> 
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm, obs),
    names_from = vital_category,
    values_from = vital_value,
    # names_prefix = "vital_wide_",
    # values_fill = NA
  ) |>
  
  #fixing temp name
  rename(temp = temp_f,
         resp = respiration) |> 
  
  # Quick min/max for duplicates at the SAME time
  select(-obs) |> 
  distinct() 

# find the duplicates by day
df_laps2_vitals_prep2 <- df_laps2_vitals_prep1 |>
  arrange(encounter_id, recorded_dttm) |>
  mutate(vital_date = date(recorded_dttm)) |> 
  group_by(encounter_id, vital_date) |>
  # mutate(n = n()) |>
  # filter(n > 1) |>
  summarise(
    temp                = fmin(temp, na.rm = TRUE),
    sbp                 = fmin(sbp, na.rm = TRUE),
    spo2                = fmin(spo2, na.rm = TRUE),
    pulse               = fmax(pulse, na.rm = TRUE),
    resp                = fmax(resp, na.rm = TRUE),
    gcs                 = fmax(gcs, na.rm = TRUE),  # remember the groupings... higher is lower gcs
    # shock_index         = fmax(shock_index, na.rm = TRUE),  # do this after

    .groups = "drop"
  ) |> 
  mutate(
    shock_index = pulse / sbp
  ) |> 
  # replace inf with NAs
  mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 

  # get rid of duplicate rows
  distinct() 




```


## vitals day one

```{r}


df_laps2_vitals_dayone_prep1 <- 
  df_encounter_laps2_temp1 |> 
  select(encounter_id, admission_dttm, discharge_dttm, dt_24hours_after_admit) |>
  distinct() |> 
  left_join(df_vitals_gcs,
            
            # join only if between the first 24 hours
            by = join_by(encounter_id, 
                         dt_24hours_after_admit >= recorded_dttm)
  ) |> 
  
    group_by(encounter_id, recorded_dttm, vital_category) |> 
  # using obs lets you get away with duplicates when going wider and can fix later!
  mutate(obs = row_number()) |> 
  ungroup() |> 
  pivot_wider(
    id_cols = c(encounter_id, recorded_dttm, obs, admission_dttm),
    names_from = vital_category,
    values_from = vital_value,
    # names_prefix = "vital_wide_",
    # values_fill = NA
  ) |>
    
  #fixing temp name
  rename(temp = temp_f,
         resp = respiration) |> 
  
  
  # Quick min/max for duplicates at the SAME time
  select(-obs) |> 
  

  distinct() 

# find the duplicates by day
df_laps2_vitals_dayone_prep2 <- df_laps2_vitals_dayone_prep1 |>
  arrange(encounter_id, recorded_dttm) |>
  
  # filter out those without a recorded_dttm so we don't add a date later
  filter(!is.na(recorded_dttm)) |> 
  
  # if we make "lab_date" the encounter date... then we are switching all labs within 24hr of admission to the "day 1" in a sneaky fashion
  #using encounter admit date to collect everything together
  mutate(vital_date = date(admission_dttm)) |> 
  group_by(encounter_id, vital_date) |>
  # mutate(n = n()) |>
  # filter(n > 1) |>
  summarise(
    temp                = fmin(temp, na.rm = TRUE),
    sbp                 = fmin(sbp, na.rm = TRUE),
    spo2                = fmin(spo2, na.rm = TRUE),
    pulse               = fmax(pulse, na.rm = TRUE),
    resp                = fmax(resp, na.rm = TRUE),
    gcs                 = fmax(gcs, na.rm = TRUE),
    # shock_index         = fmax(shock_index, na.rm = TRUE),  # do this after

    .groups = "drop"
  ) |> 
  mutate(
    shock_index         = pulse / sbp
  ) |> 
  
  # replace inf with NAs
  mutate(across(where(is.numeric) & !c(encounter_id), ~ na_if(.x, is.infinite(.x)))) |> 

  # get rid of duplicate rows
  distinct() 

# switch out the day 1 stuff 
df_laps2_vitals_final <- df_laps2_vitals_prep2 |> anti_join(df_laps2_vitals_dayone_prep2 |> 
                              select(encounter_id, vital_date)) |> 
  bind_rows(df_laps2_vitals_dayone_prep2) |> 
  arrange(encounter_id, vital_date) |> 
  
  # drop rows with no recorded date
  filter(!is.na(vital_date))



```



## Laps2 code

```{r}

df_laps_calc <- df_laps2_final |> 
  # get same naming for date
  rename(recorded_date = lab_date) |> 
  full_join(df_laps2_vitals_final |> 
              rename(recorded_date = vital_date),
            join_by(encounter_id, recorded_date)
            ) |> 
  full_join(df_pre_laps_final)
  
df_laps2_scores <- df_laps_calc |> 
  group_by(encounter_id, recorded_date) |> 
  mutate(
    laps2 = 0,
    # lactic_acid and pH 
    laps2 = fcase(
      
      # missing data
      is.na(ph_arterial)  &                      is.na(lactic_acid) & high_risk == 0 , laps2 + 0,
      is.na(ph_arterial)  &                      is.na(lactic_acid) & high_risk == 1 , laps2 + 15,
      is.na(ph_arterial)  &                      lactic_acid < 2    & high_risk == 0 , laps2 + 0,
      is.na(ph_arterial)  &                      lactic_acid < 2    & high_risk == 1 , laps2 + 12,
      is.na(ph_arterial)  &     lactic_acid >= 2   & lactic_acid < 4    & high_risk == 0 , laps2 + 12,
      is.na(ph_arterial)  &     lactic_acid >= 2   & lactic_acid < 4    & high_risk == 1 , laps2 + 15,
      is.na(ph_arterial)  &                      lactic_acid >= 4   & high_risk == 0 , laps2 + 26,
      is.na(ph_arterial)  &                      lactic_acid >= 4   & high_risk == 1 , laps2 + 30,
      ph_arterial < 7.2   &                      is.na(lactic_acid) & high_risk == 0 , laps2 + 13,
      ph_arterial < 7.2   &                      is.na(lactic_acid) & high_risk == 1 , laps2 + 19,
      ph_arterial >= 7.2  & ph_arterial < 7.35 & is.na(lactic_acid) & high_risk == 0 , laps2 + 5,
      ph_arterial >= 7.2  & ph_arterial < 7.35 & is.na(lactic_acid) & high_risk == 1 , laps2 + 15,
      ph_arterial >= 7.35 & ph_arterial < 7.45 & is.na(lactic_acid) & high_risk == 0 , laps2 + 0,
      ph_arterial >= 7.35 & ph_arterial < 7.45 & is.na(lactic_acid) & high_risk == 1 , laps2 + 12,
      ph_arterial >= 7.45 &                      is.na(lactic_acid) & high_risk == 0 , laps2 + 12,
      ph_arterial >= 7.45 &                      is.na(lactic_acid) & high_risk == 1 , laps2 + 15,

      # complete data
      ph_arterial < 7.2   &                      lactic_acid <  2                   , laps2 + 13,
      ph_arterial < 7.2   &     lactic_acid >= 2   & lactic_acid <  4                   , laps2 + 19,
      ph_arterial < 7.2   &                      lactic_acid >= 4                   , laps2 + 34,
      ph_arterial >= 7.2  & ph_arterial < 7.35 & lactic_acid <  2                   , laps2 + 5,
      ph_arterial >= 7.2  & ph_arterial < 7.35 & lactic_acid >= 2 & lactic_acid < 4     , laps2 + 15,
      ph_arterial >= 7.2  & ph_arterial < 7.35 & lactic_acid >= 4                   , laps2 + 25,
      ph_arterial >= 7.35 & ph_arterial < 7.45 & lactic_acid <  2                   , laps2 + 0,
      ph_arterial >= 7.35 & ph_arterial < 7.45 & lactic_acid >= 2 & lactic_acid < 4     , laps2 + 12,
      ph_arterial >= 7.35 & ph_arterial < 7.45 & lactic_acid >= 4                   , laps2 + 26,
      ph_arterial >= 7.45 &                      lactic_acid <  2                   , laps2 + 12,
      ph_arterial >= 7.45 &     lactic_acid >= 2 &   lactic_acid <  4                   , laps2 + 15,
      ph_arterial >= 7.45 &                      lactic_acid >= 4                   , laps2 + 30,
      default                                                                   = laps2
      ),
    
    # Sodium
    laps2 = fcase(
      is.na(sodium)                                                             , laps2 + 0,
      sodium <  129                                                             , laps2 + 14,
      sodium >= 129 & sodium < 135                                              , laps2 + 7,
      sodium >= 135 & sodium < 146                                              , laps2 + 0,
      sodium >= 146                                                             , laps2 + 4,
      default                                                                   = laps2
    ),
    
    # Bilirubin
    laps2 = fcase(
      is.na(bilirubin_total)                                                    , laps2 + 0,
      bilirubin_total <  2                                                      , laps2 + 0,
      bilirubin_total >= 2 & bilirubin_total < 3                                , laps2 + 11,
      bilirubin_total >= 3 & bilirubin_total < 5                                , laps2 + 18,
      bilirubin_total >= 5 & bilirubin_total < 8                                , laps2 + 25,
      bilirubin_total >= 8                                                      , laps2 + 41,
      TRUE , laps2
    ),
    
    # BUN
    laps2 = fcase(
      is.na(bun)                                                                , laps2 + 0,
      bun < 18                                                                  , laps2 + 0,
      bun >= 18 & bun < 20                                                      , laps2 + 11,
      bun >= 20 & bun < 40                                                      , laps2 + 12,
      bun >= 40 & bun < 80                                                      , laps2 + 20,
      bun >= 80                                                                 , laps2 + 25,
      default                                                                   = laps2
    ),
    
    # Creatinine
    laps2 = fcase(
      is.na(creatinine)                                                         , laps2 + 0,
      creatinine < 1                                                            , laps2 + 0,
      creatinine >= 1 & creatinine < 2                                          , laps2 + 6,
      creatinine >= 2 & creatinine < 4                                          , laps2 + 11,
      creatinine >= 4                                                           , laps2 + 5,
      default                                                                   = laps2
    ),
    
    # BUN/Cr Ratio
    laps2 = fcase(
      is.na(bun_cr_ratio)                                                       , laps2 + 0,
      bun_cr_ratio < 25                                                         , laps2 + 0,
      bun_cr_ratio >= 25                                                        , laps2 + 10,
      default                                                                   = laps2
    ),
    
    # Albumin
    laps2 = fcase(
      is.na(albumin)                                                            , laps2 + 0,
      albumin < 2                                                               , laps2 + 31,
      albumin >= 2 & albumin < 2.5                                              , laps2 + 15,
      albumin >= 2.5                                                            , laps2 + 0,
      default                                                                   = laps2
    ),
    
    # glucose_serum
    laps2 = fcase(
      is.na(glucose_serum)                                                            , laps2 + 0,
      glucose_serum < 40                                                              , laps2 + 10,
      glucose_serum >= 40 & glucose_serum < 60                                              , laps2 + 10,
      glucose_serum >= 60 & glucose_serum < 200                                             , laps2 + 0,
      glucose_serum >= 200                                                            , laps2 + 3,
      default                                                                   = laps2
    ),
    
    # Hematocrit (Hct)
    laps2 = fcase(
      is.na(hematocrit)                                                         , laps2 + 0,
      hematocrit < 20                                                           , laps2 + 7,
      hematocrit >= 20 & hematocrit < 40                                        , laps2 + 8,
      hematocrit >= 40 & hematocrit < 50                                        , laps2 + 0,
      hematocrit >= 50                                                          , laps2 + 3,
      default                                                                   = laps2
    ),
    
    # WBC
    laps2 = fcase(
      is.na(wbc) &                                               high_risk == 0 , laps2 + 0,
      is.na(wbc) &                                               high_risk == 1 , laps2 + 32,
      wbc < 5                                                                   , laps2 + 8,
      wbc >= 5 & wbc < 13                                                       , laps2 + 0,
      wbc >= 13                                                                 , laps2 + 11,
      default                                                                   = laps2
    ),
    
  # PaCO2
    laps2 = fcase(
      is.na(paco2)                                                              , laps2 + 0,
      paco2 < 35                                                                , laps2 + 7,
      paco2 >= 35 & paco2 < 45                                                  , laps2 + 0,
      paco2 >= 45 & paco2 < 55                                                  , laps2 + 11,
      paco2 >= 55 & paco2 < 65                                                  , laps2 + 13,
      paco2 >= 65                                                               , laps2 + 12,
      default                                                                   = laps2
    ),
  
  # PaO2
    laps2 = fcase(
      is.na(pao2)                                                               , laps2 + 0,
      pao2 < 50                                                                 , laps2 + 8,
      pao2 >= 50 & pao2 < 120                                                   , laps2 + 0,
      pao2 >= 120                                                               , laps2 + 12,
      default                                                                   = laps2
    ),
  
  # Troponin
    laps2 = fcase(
      is.na(troponin)  &                                       high_risk == 0 , laps2 + 0,
      is.na(troponin)  &                                       high_risk == 1 , laps2 + 9,
      troponin <  0.01                                                        , laps2 + 0,
      troponin >= 0.01 & troponin < 0.2                                     , laps2 + 8,
      troponin >= 0.2  & troponin < 1                                       , laps2 + 17,
      troponin >= 1    & troponin < 3                                       , laps2 + 19,
      troponin >= 3                                                           , laps2 + 25,
      default                                                                   = laps2
    ),
  
  # Temp
    laps2 = fcase(
      is.na(temp)                                                               , laps2 + 0,
      temp < 96                                                                 , laps2 + 20,
      temp >= 96    & temp < 100.5                                              , laps2 + 0,
      temp >= 100.5                                                             , laps2 + 3,
      default                                                                   = laps2
    ),

  # Pulse
    laps2 = fcase(
      is.na(pulse)                                                              , laps2 + 0,
      pulse < 60                                                                , laps2 + 7,
      pulse >= 60  & pulse < 110                                                , laps2 + 0,
      pulse >= 110 & pulse < 140                                                , laps2 + 7,
      pulse >= 140                                                              , laps2 + 10,
      default                                                                   = laps2
    ),
  
  # Resp
    laps2 = fcase(
      is.na(resp)                                                               , laps2 + 0,
      resp < 20                                                                 , laps2 + 0,
      resp >= 20 & resp < 30                                                    , laps2 + 11,
      resp >= 30                                                                , laps2 + 21,
      default                                                                   = laps2
    ),
    
  # SBP
    laps2 = fcase(
      is.na(sbp)                                                                , laps2 + 0,
      sbp < 75                                                                  , laps2 + 22,
      sbp >= 75  & sbp < 90                                                     , laps2 + 13,
      sbp >= 90  & sbp < 120                                                    , laps2 + 5,
      sbp >= 120 & sbp < 140                                                    , laps2 + 0,
      sbp >= 140 & sbp < 160                                                    , laps2 + 8,
      sbp >= 160                                                                , laps2 + 14,
      default                                                                   = laps2
    ),
  
  # Shock
    laps2 = fcase(
      is.na(shock_index)                                                        , laps2 + 0,
      shock_index < 0.65                                                        , laps2 + 0,
      shock_index >= 0.65 & shock_index < 0.85                                  , laps2 + 8,
      shock_index >= 0.85                                                       , laps2 + 17,
      default                                                                   = laps2
    ),
  
  # O2Sat
    laps2 = fcase(
      is.na(spo2) &                                              high_risk == 0 , laps2 + 0,
      is.na(spo2) &                                              high_risk == 1 , laps2 + 22,
      spo2 <  90                                                                , laps2 + 22,
      spo2 >= 90  & spo2 < 94                                                   , laps2 + 12,
      spo2 >  94                                                                , laps2 + 0,
      default                                                                   = laps2
    ),
  
  # Neuro (GCS)
    laps2 = fcase(
      is.na(gcs) &                                               high_risk == 0 , laps2 + 16,
      is.na(gcs) &                                               high_risk == 1 , laps2 + 21,
      gcs == 1                                                                  , laps2 + 0,
      gcs == 2                                                                  , laps2 + 16,
      gcs == 3                                                                  , laps2 + 21,
      gcs == 4                                                                  , laps2 + 36,
      default                                                                   = laps2
    )
  )

  

```

## PF Ratio

```{r}

clif_pao2 <- import_df("clif_vitals") |> filter(vital_category == "pao2") 

clif_fio2 <- clif_respiratory_support |> filter(!is.na(fio2_set)) |> select(encounter_id, recorded_dttm, fio2_set)

```


# Analysis

## analysis 1
propensity score match M/F on LAPS2, age, pf ratio
- need to decide when we prop match
- ? first 24 hrs of ventilation.  

regress gender on Vt/IBW... what does female gender do for getting LTVV
add ht to regression
? prop match after this

use a for loop to see how this changes over time, run the regression on each MV day


## Table 3 Predictors of Mode Variation / Trach Variation / LTVV Variation / Prone Variation

```{r}

test


```

